{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e292b979-e7de-47e5-b6e6-f3795c44400b",
   "metadata": {},
   "source": [
    "## Geneious analysis for individual samples from raw Geneious output, \"Annotation.csv\" \n",
    "\n",
    " ### Required packages\n",
    " - No specific package required \n",
    " \n",
    " ### Inputs\n",
    " - Geneious SNP analysis of _k13_, _crt_, _mdr1_, _dhfr_, _dhps_, and _cytb_\n",
    " - Documentation on Geneious analysis can be found: Readme.md\n",
    " - Geneious outputs were modified to GuineaAnalysis_Individual.csv from \"Annotation.csv\"\n",
    " \n",
    " \n",
    " ### Data structure \n",
    " - [Long-form](https://seaborn.pydata.org/tutorial/data_structure.html#long-form-vs-wide-form-data) \n",
    "     - Each variable is a column \n",
    "\n",
    "         - \"Sample\" = *AMD ID*, including associated meta-data for each sample\n",
    "             - AMD ID and bit code key is found under MS Teams > Domestic > Files > Sample Naming > Sample_naming_key.pptx  \n",
    "\n",
    "             - Key: **Year Country State/Site DayofTreatment Treatment SampleID Genus SampleType GeneMarker-8bitcode SampleSeqCount**\n",
    "\n",
    "                 - Example:\n",
    "                     - Individual sequenced sample ID: 17GNDo00F0001PfF1290 = 2017 Guinea Dorota Day0 AS+AQ 0001 P.falciparum FilterBloodSpot k13-crt-mdr-dhfr-dhps-cytB-cpmp-pfs47 \n",
    "\n",
    "                     - Pooled sequenced sample ID: 17GNDoxxx001P10F1290 = 2017 Guinea Dorota **xx x** 001 **Pooled SamplesInPool** P.falciparum FilterBloodSpot k13-crt-mdr-dhfr-dhps-cytB-cpmp-pfs47 \n",
    "\n",
    "                         - NOTE: If information is not availble (na) **x** is used. For pooled samples, DayofTreatment and Treatment is na since its a pool of multiple samples with that info. \n",
    "                         - NOTE: For pooled samples, **Genus** is replaced with **Pooled** and **SampleType** with **SamplesInPool** to indicated this as a pooled sequenced sample and sample count in each pool. \n",
    "         <p>&nbsp;</p>\n",
    "         - \"Year\" = the year the study was conducted \n",
    "         - \"Site\" = the state or province \n",
    "         - \"Day_of_treatment\" = describes the day of treatment provided to the patient \n",
    "         - \"Gene\" = drug resistant gene(s) \n",
    "         - \"G_annotation\" = full SNP annotation in the following format: WildTypeAA-CodonPosition-MutantAA \n",
    "         - \"Coverage\" = the number of reads covering the SNP \n",
    "         - \"VAF\" = variant allele frequency calculated by AA divided by total reads in loci \n",
    "         - \"SNP\" = single nucleotide polymorphism in WildTypeAA or MutantAA annotation format \n",
    "         - \"Type\" = describes if it is a wild type or mutant SNP \n",
    "\n",
    "     - Each observation is a row for each sample ID (patient ID) \n",
    " \n",
    " #### TODO\n",
    " \n",
    " #### Activity Name\n",
    " - [ ] Write doc.string at the beginning of the code\n",
    " - [ ] Write detailed description with comment for line by line\n",
    " - [ ] Make the code more simple and accurate\n",
    " - [ ] Follow zen of python\n",
    "    \n",
    " #### Completed Activity âœ“\n",
    " - [x] Created marked down at the beginning of the file for description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83bfdd5a-14d1-4bdd-bfac-48e4f7ac2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117/2388402328.py:3: DtypeWarning: Columns (16,19,24,26,28,30,31,32,33,34,35,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,57,58,59,60,61,62,64,65,66,67,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Geneious_DF=pd.read_csv(\"Annotations.csv\") ##Import raw Geneious output for variant analysis\n",
      "/tmp/ipykernel_117/2388402328.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Geneious_DF_N1[\"TrackerSNP\"]=Geneious_DF_N1[\"Amino Acid Change\"].astype(str).str[0]+Geneious_DF_N1[\"CDS Codon Number\"].astype(int).astype(str)+Geneious_DF_N1[\"Amino Acid Change\"].astype(str).str[-1] ##Create a TrackerSNP Column which has both amino acid before the change and after the change\n",
      "/tmp/ipykernel_117/2388402328.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Combination_filtered[\"SITE\"]=Combination_filtered.apply(site, axis=1) ##Apply the functions defined previously\n",
      "/tmp/ipykernel_117/2388402328.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Combination_filtered[\"TreatmentDay\"]=Combination_filtered.apply(TreatmentDay, axis=1)\n",
      "/tmp/ipykernel_117/2388402328.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Combination_filtered[\"Pooled\"]=Combination_filtered.apply(Pooled, axis=1)\n",
      "/tmp/ipykernel_117/2388402328.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Combination_filtered[\"Year\"]=Combination_filtered.apply(year, axis=1)\n",
      "/tmp/ipykernel_117/2388402328.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Combination_filtered[\"TYPE\"]=Combination_filtered.apply(type, axis=1)\n",
      "/tmp/ipykernel_117/2388402328.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Combination_filtered[\"SNP\"]=Combination_filtered.apply(SNP, axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd ## Import Pandas library for processing dataframe as pd\n",
    "import numpy as np ## Import Numy for processing matrix as np\n",
    "Geneious_DF=pd.read_csv(\"Annotations.csv\") ##Import raw Geneious output for variant analysis\n",
    "Geneious_DF_N1=Geneious_DF[(Geneious_DF['Type']=='Polymorphism') & (Geneious_DF['Amino Acid Change'].notnull())] ##If the type column contains polymorphism and Amino Acid Change column is not empty then create a dataframe satisfying those conditions\n",
    "\n",
    "Geneious_DF_N2=Geneious_DF[Geneious_DF['Type']=='Coverage - High'] ##If the Coverage - High is in the type column as value then select dataframe for those column values\n",
    "\n",
    "Geneious_DF_N1[\"TrackerSNP\"]=Geneious_DF_N1[\"Amino Acid Change\"].astype(str).str[0]+Geneious_DF_N1[\"CDS Codon Number\"].astype(int).astype(str)+Geneious_DF_N1[\"Amino Acid Change\"].astype(str).str[-1] ##Create a TrackerSNP Column which has both amino acid before the change and after the change\n",
    "\n",
    "Combine_Variant_Wildtpye = [Geneious_DF_N1, Geneious_DF_N2] ##Produce a complete dataframe which contains both variants and wildtypes\n",
    "Combation_Vi_Wi = pd.concat(Combine_Variant_Wildtpye) ##Concatenate the dataframes for variants and wildtypes\n",
    "Combination_filtered=Combation_Vi_Wi.drop_duplicates(subset =[\"Document Name\", \"TrackerSNP\"] )  ##Drop duplicates meaning if the values are already in variants then drop it from the wildtypes\n",
    "##The dataframe contains information, \"Sample,Pooled,Year,SITE,TreatmentDay,GENE,G_annotation,COVERAGE,VAF,VF,SNP,TYPE\\n\")\n",
    "        \n",
    "def site(row): ##Set up a function for assignging site based on the values in the document name column\n",
    "    if row['Document Name'][4:6]==\"Ha\":\n",
    "        return 'Hamdalaye'\n",
    "    elif row['Document Name'][4:6]==\"Do\":\n",
    "        return 'Dorota'\n",
    "    elif row['Document Name'][4:6]==\"Ma\":\n",
    "        return 'Maferinyah'\n",
    "    elif row['Document Name'][4:6]==\"La\":\n",
    "        return 'Lay-Sare'\n",
    "    elif row['Document Name'][4:6]==\"LS\":\n",
    "        return 'Lay-Sare'\n",
    "    \n",
    "def TreatmentDay(row): ##Set up a function for assigning TreatmentDay based on the values in the document name column\n",
    "    if row['Document Name'][6:8]==\"00\":\n",
    "        return '0'\n",
    "    elif row['Document Name'][6:8]==\"1A\":\n",
    "        return '1'\n",
    "    elif row['Document Name'][6:8]!=\"00\" and row['Document Name'][6:8]!=\"1A\":\n",
    "        return row['Document Name'][6:8]\n",
    "    \n",
    "def Pooled(row): ##Set up a function for Pooled based on the values in the document name column\n",
    "    if row['Document Name'][8:10]==\"xp\":\n",
    "        return 'pooled'\n",
    "    elif row['Document Name'][8:10]!=\"xp\":\n",
    "        return 'individual'\n",
    "\n",
    "def year(row):  ##Set up a function for Year  based on the values in the document name column\n",
    "    return row['Document Name'][0:2]\n",
    "\n",
    "def type(row):  ##Set up a TYPE column based on given value in the Type whether it is mutation or wildtype\n",
    "    if row['Type'] =='Polymorphism':\n",
    "        return \"mutation\"\n",
    "    if row['Type'] =='Coverage - High':\n",
    "        return \"wildtype\"\n",
    "    \n",
    "def SNP(row):  ##Set up a SNP column to give pre or post amino acid changes based on mutation or wildtype\n",
    "    if row['Type'] =='Polymorphism':\n",
    "        return row['TrackerSNP'][1::]\n",
    "    if row['Type'] =='Coverage - High':\n",
    "        return row['TrackerSNP'][0:-1]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "Combination_filtered[\"SITE\"]=Combination_filtered.apply(site, axis=1) ##Apply the functions defined previously\n",
    "Combination_filtered[\"TreatmentDay\"]=Combination_filtered.apply(TreatmentDay, axis=1)\n",
    "Combination_filtered[\"Pooled\"]=Combination_filtered.apply(Pooled, axis=1)\n",
    "Combination_filtered[\"Year\"]=Combination_filtered.apply(year, axis=1)\n",
    "Combination_filtered[\"TYPE\"]=Combination_filtered.apply(type, axis=1)\n",
    "Combination_filtered[\"SNP\"]=Combination_filtered.apply(SNP, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "Combination_report1=Combination_filtered[Combination_filtered['Type']=='Polymorphism'] ##Select columns with mutations\n",
    "Combination_report2=Combination_filtered[Combination_filtered['Type']=='Coverage - High'] ##Select columns with wildtypes\n",
    "final_report1=Combination_report1[[\"Document Name\",\"Sequence Name\",\"SITE\",\"TreatmentDay\",\"Pooled\",\"Year\",\"Coverage\",\"Variant Frequency\",\"Variant Raw Frequency\",\"TrackerSNP\",\"TYPE\",\"SNP\"]] ##Assign sample information to samples with mutation\n",
    "final_report2=Combination_report2[[\"Document Name\",\"Sequence Name\",\"SITE\",\"TreatmentDay\",\"Pooled\",\"Year\",\"Average Coverage\",\"Variant Frequency\",\"Variant Raw Frequency\",\"TrackerSNP\",\"TYPE\",\"SNP\"]] ##Assign sample information to samples with wildtypes\n",
    "final_report2_re=final_report2.rename(columns={'Average Coverage': 'Coverage'}) ##Change the name of average coverage to coverage for samples with wildtypes\n",
    "final_combine=[final_report1, final_report2_re] ##Combine the information from wildtypes and mutations into one dataframe\n",
    "final_combine_2=pd.concat(final_combine) ##concatenate\n",
    "final_combine_2.to_csv(\"test.csv\", sep=',', index=False) ##Create a file with the dataframe for testing purpose\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bc46cb9f-c06f-435b-96cb-45ebd104f1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        100.0\n",
      "1        100.0\n",
      "2        100.0\n",
      "3        100.0\n",
      "4        100.0\n",
      "         ...  \n",
      "11444      NaN\n",
      "11445      NaN\n",
      "11446      NaN\n",
      "11447      NaN\n",
      "11448      NaN\n",
      "Name: Variant Frequency, Length: 11449, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117/1774320522.py:19: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_merged_poolsize = df_merged_poolsize.drop('SITE_y', 1) ##Get rid of duplicate columns which is SITE_y\n",
      "/tmp/ipykernel_117/1774320522.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_merged_poolsize = df_merged_poolsize.drop('YEAR', 1) ##Get rid of duplicate columns which is year\n"
     ]
    }
   ],
   "source": [
    "pooled_part1=pd.read_csv(\"Pooled_Info_Part1.csv\") ##import a file with information about pooled samples\n",
    "pooled_part2=pd.read_csv(\"Pooled_Info_Part2_fixed.csv\")  ##import a file with information about pooled samples\n",
    "\n",
    "Combine_pooled_parts = [pooled_part1[[\"Pool\",\"SITE\",\"YEAR\",\"AMD_ID\",\"Poolsize\"]], pooled_part2[[\"Pool\",\"SITE\",\"YEAR\",\"AMD_ID\",\"Poolsize\"]]]\n",
    "Combation_pooled_concatenate = pd.concat(Combine_pooled_parts) ##Combine and concatenate the two pooled files\n",
    "\n",
    "Combation_pooled_concatenate.to_csv(\"test-pre1.csv\", sep=',', index=False) ##create file for testing purpose\n",
    "\n",
    "def name(row):\n",
    "    return row['Document Name'].split(\"_\")[0]\n",
    "\n",
    "final_combine_2[\"Document Name\"]=final_combine_2.apply(name, axis=1) ##Clean the document name which is the AMD_ID to get rid of the Geneious information\n",
    "\n",
    "final_combine_2.rename(columns={'Document Name':'AMD_ID'}, inplace=True) ##Reanme the document name to AMD_ID\n",
    "\n",
    "\n",
    "df_merged_poolsize = pd.merge(final_combine_2, Combation_pooled_concatenate, on=['AMD_ID'], how='left') ##merge the information based on AMD_ID to add pooled columns and pooled size columns\n",
    "\n",
    "df_merged_poolsize = df_merged_poolsize.drop('SITE_y', 1) ##Get rid of duplicate columns which is SITE_y\n",
    "df_merged_poolsize = df_merged_poolsize.drop('YEAR', 1) ##Get rid of duplicate columns which is year\n",
    "\n",
    "df_merged_poolsize.Poolsize.fillna(value=1, inplace=True) ##Fill empty values for poolsize for individual with 1s\n",
    "\n",
    "df_merged_poolsize['Variant Frequency'] = df_merged_poolsize['Variant Frequency'].fillna(0)\n",
    "\n",
    "print(df_merged_poolsize[\"Variant Frequency\"].str.split('%').str[0].str.strip(\"%\"))\n",
    "\n",
    "df_merged_poolsize[\"Prod\"]=df_merged_poolsize[\"Variant Frequency\"].str.split('%').str[0].str.strip(\"%\").astype(float)*df_merged_poolsize[\"Poolsize\"].astype(float)\n",
    "\n",
    "df_merged_poolsize.to_csv(\"test2.csv\", sep=',', index=False) ##Generate file to test\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fbdafdd2-4e85-441f-a444-7ae3318ad7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117/1093668165.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_merged_countv = df_merged_countv.drop('Pool', 1) ##drop pooled information\n",
      "/tmp/ipykernel_117/1093668165.py:55: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_merged_countv = df_merged_countv.drop('Prod', 1) ##drop pooled information\n",
      "/tmp/ipykernel_117/1093668165.py:56: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_merged_countv = df_merged_countv.drop('sum', 1) ##drop pooled information\n"
     ]
    }
   ],
   "source": [
    "df_merged_poolsize = df_merged_poolsize[~df_merged_poolsize.AMD_ID.isin([\"17GNHa16F0011PfF1290\",\"17GNHa21F0165PfF1290\",\"18GNMa21A0014PfF1290\",\"18GNMa1A0129PfF1290\",\"18GNLS21A0012PfF1290\",\"18GNLS21A0103PfF1290\",\"18GNLS21A0136PfF1290\",\"18GNLS14F0141PfF1290\",\"19GNHa14A0077PfF1290\"])] ##check for day of failure for recrudescence\n",
    "#[\"17GNHa16F0011PfF1290\",\"17GNHa21F0165PfF1290\",\"18GNMa21A0014PfF1290\",\"18GNMa1A0129PfF1290\",\"18GNLS21A0012PfF1290\",\"18GNLS21A0103PfF1290\",\"18GNLS21A0136PfF1290\",\"18GNLS14F0141PfF1290\",\"19GNHa14A0077PfF1290\"]\n",
    "\n",
    "\n",
    "df_merged_count=df_merged_poolsize.groupby(['SITE_x','Sequence Name','TrackerSNP', 'Pooled']).sum()  ##Sum the columns based on overlapping values on site, trackersnp, and pooled\n",
    "df_merged_countv=df_merged_poolsize.groupby(['SITE_x','Sequence Name','TrackerSNP', 'Pooled', 'SNP']).sum() ##Sum the columns based on agreeing values on site, trackersnp, and pooled, and snp\n",
    "df_merged_count=df_merged_count.groupby(['SITE_x','Sequence Name','TrackerSNP']).sum() ##Sum again based on stie and tracker snp\n",
    "df_merged_countv=df_merged_countv.groupby(['SITE_x','Sequence Name','TrackerSNP','SNP']).sum() ##Sum again based on site, tracker, and snp\n",
    "df_merged_countv = df_merged_countv.drop('Pool', 1) ##drop pooled information\n",
    "\n",
    "#df_merged_countv.to_csv(\"testtest2.csv\", sep=',', index=True)\n",
    "\n",
    "#df_merged_countv.to_csv(\"testtest1.csv\", sep=',', index=True)\n",
    "\n",
    "df_merged_countv=df_merged_countv.reset_index()  ##Reset index so  that we can  use the columns\n",
    "df_merged_countv['Type'] = np.where(df_merged_countv['SNP'].str[0].str.isdigit(), \"Mutation\" , \"WildType\") ##If the first character of SNP value is digit assign mutation  else assign wildtype\n",
    "df_merged_countv.rename(columns={'Poolsize':'Number_of_samples'}, inplace=True) ##Reanme the Poolsize to number  of samples\n",
    "df_merged_countvp=df_merged_countv  ##Create another dataframe from previous dataframe this is for calculating products for VAF\n",
    "df_merged_countv=df_merged_countv.pivot(index=[\"SITE_x\", 'Sequence Name', \"TrackerSNP\"], columns=\"Type\", values=\"Number_of_samples\") ##pivot and align mutation and wildtype\n",
    "df_merged_countvp=df_merged_countvp.pivot(index=[\"SITE_x\", 'Sequence Name',\"TrackerSNP\"], columns=\"Type\", values=\"Prod\") ##pivot and align mutation and wildtype\n",
    "\n",
    "#df_merged_countvp.to_csv(\"testtest1.csv\", sep=',', index=True)\n",
    "\n",
    "\"\"\"\n",
    "To do: \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n",
    "This is where I am stuck. Trying using pivot to fix it\n",
    "\"\"\"\n",
    "\n",
    "df_merged_countvp=df_merged_countvp.reset_index() ##Reset indexes\n",
    "df_merged_countv=df_merged_countv.reset_index()  ##Reset indexes\n",
    "\n",
    "df_merged_countv['SNP'] = np.where(pd.isna(df_merged_countv['Mutation']), df_merged_countv['TrackerSNP'].astype(str).str[0:-1], df_merged_countv['TrackerSNP'].astype(str).str[1::]) ##Depending on codntion where mutation value is nan or not assign SNP with just first character or last character and amino acid position\n",
    "cols = list(df_merged_countv.columns)\n",
    "cols = cols[0:3] + cols[5:6] + cols[3:5]\n",
    "df_merged_countv = df_merged_countv[cols]\n",
    "df_merged_countv.rename(columns={'TrackerSNP':'G_Annotation'}, inplace=True)\n",
    "\n",
    "df_merged_countv['Prod']= df_merged_countvp['Mutation']\n",
    "\n",
    "df_merged_countv['Prod'] = df_merged_countv['Prod'].fillna(0)\n",
    "\n",
    "df_merged_countv['Mutation'] = df_merged_countv['Mutation'].fillna(0)\n",
    "\n",
    "df_merged_countv['WildType'] = df_merged_countv['WildType'].fillna(0)\n",
    "\n",
    "df_merged_countv['sum'] = df_merged_countv['Mutation'] + df_merged_countv['WildType']\n",
    "\n",
    "df_merged_countv['div'] = df_merged_countv['Prod'] / df_merged_countv['sum']\n",
    "\n",
    "df_merged_countv['div']=df_merged_countv['div'].round(2)\n",
    "\n",
    "df_merged_countv['div']=np.where(pd.isna(df_merged_countv['div']),\"\", df_merged_countv['div'].astype(str)+\"%\") \n",
    "\n",
    "df_merged_countv = df_merged_countv.drop('Prod', 1) ##drop pooled information\n",
    "df_merged_countv = df_merged_countv.drop('sum', 1) ##drop pooled information\n",
    "\n",
    "df_merged_countv.rename(columns={'div':'VAF'}, inplace=True)\n",
    "\n",
    "df_merged_countv.to_csv(\"testtest4.csv\", sep=',', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9217d2-e75e-430f-9343-ea5698d4c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_poolsize[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
